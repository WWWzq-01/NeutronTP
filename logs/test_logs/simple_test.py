#!/usr/bin/env python3
"""
ç®€å•çš„æµ‹è¯•è„šæœ¬æ¥éªŒè¯ä¿¡æ¯äº’é¦ˆç³»ç»Ÿçš„ä¿®å¤
"""

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("æµ‹è¯•åŸºæœ¬åŠŸèƒ½...")
    
    try:
        # æµ‹è¯•å¯¼å…¥
        print("æ­£åœ¨å¯¼å…¥æ¨¡å—...")
        
        # æ¨¡æ‹ŸPyTorchå¼ é‡
        class MockTensor:
            def __init__(self, data):
                self.data = data
                self.grad = None
            
            def item(self):
                return self.data
            
            def norm(self):
                return MockTensor(abs(self.data))
            
            def detach(self):
                return self
            
            def clone(self):
                return MockTensor(self.data)
            
            def size(self, dim=None):
                if dim is None:
                    return (len(self.data),)
                return len(self.data)
        
        # æ¨¡æ‹ŸèŠ‚ç‚¹æ”¶æ•›è·Ÿè¸ªå™¨
        class MockConvergenceTracker:
            def __init__(self, num_nodes):
                self.num_nodes = num_nodes
                self.node_loss_history = {}
                self.node_grad_history = {}
                self.node_embedding_history = {}
                self.converged_nodes = set()
            
            def update_node_info(self, node_ids, losses, gradients, embeddings, epoch):
                print(f"æ›´æ–°èŠ‚ç‚¹ä¿¡æ¯: {len(node_ids)} ä¸ªèŠ‚ç‚¹, epoch {epoch}")
                
                for i, node_id in enumerate(node_ids):
                    node_id = node_id.item()
                    if node_id < self.num_nodes:
                        # è®°å½•æŸå¤±
                        if node_id not in self.node_loss_history:
                            self.node_loss_history[node_id] = []
                        self.node_loss_history[node_id].append(losses[i].item())
                        
                        # è®°å½•æ¢¯åº¦ï¼ˆä½¿ç”¨æŸå¤±ä½œä¸ºæ›¿ä»£ï¼‰
                        if node_id not in self.node_grad_history:
                            self.node_grad_history[node_id] = []
                        
                        if gradients is not None and i < gradients.size(0):
                            if gradients[i].dim() == 0:
                                grad_value = gradients[i].item()
                            else:
                                grad_value = gradients[i].norm().item()
                        else:
                            grad_value = losses[i].item()
                        
                        self.node_grad_history[node_id].append(grad_value)
                        
                        # è®°å½•åµŒå…¥
                        if node_id not in self.node_embedding_history:
                            self.node_embedding_history[node_id] = []
                        
                        if embeddings is not None and i < embeddings.size(0):
                            self.node_embedding_history[node_id].append(embeddings[i].detach().clone())
                        else:
                            # åˆ›å»ºè™šæ‹ŸåµŒå…¥
                            dummy_embedding = MockTensor([0.0] * 64)
                            self.node_embedding_history[node_id].append(dummy_embedding)
                
                print(f"âœ“ æˆåŠŸæ›´æ–° {len(node_ids)} ä¸ªèŠ‚ç‚¹çš„ä¿¡æ¯")
                return True
        
        # æµ‹è¯•
        tracker = MockConvergenceTracker(100)
        
        # æ¨¡æ‹Ÿæ•°æ®
        node_ids = MockTensor([0, 1, 2, 3, 4])
        losses = MockTensor([0.5, 0.3, 0.8, 0.2, 0.6])
        gradients = MockTensor([0.1, 0.05, 0.15, 0.02, 0.12])
        embeddings = [MockTensor([0.1] * 64) for _ in range(5)]
        
        # æµ‹è¯•æ›´æ–°
        result = tracker.update_node_info(node_ids, losses, gradients, embeddings, epoch=1)
        
        if result:
            print("âœ“ åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("âœ— åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\næµ‹è¯•è¾¹ç•Œæƒ…å†µ...")
    
    try:
        class MockConvergenceTracker:
            def __init__(self, num_nodes):
                self.num_nodes = num_nodes
                self.node_loss_history = {}
                self.node_grad_history = {}
                self.node_embedding_history = {}
                self.converged_nodes = set()
            
            def update_node_info(self, node_ids, losses, gradients, embeddings, epoch):
                print(f"è¾¹ç•Œæµ‹è¯•: {len(node_ids)} ä¸ªèŠ‚ç‚¹")
                
                # æµ‹è¯•ç©ºæ•°æ®
                if len(node_ids) == 0:
                    print("âœ“ ç©ºæ•°æ®å¤„ç†æˆåŠŸ")
                    return True
                
                # æµ‹è¯•Noneå€¼
                if gradients is None:
                    print("âœ“ Noneæ¢¯åº¦å¤„ç†æˆåŠŸ")
                
                if embeddings is None:
                    print("âœ“ NoneåµŒå…¥å¤„ç†æˆåŠŸ")
                
                return True
        
        tracker = MockConvergenceTracker(100)
        
        # æµ‹è¯•ç©ºæ•°æ®
        empty_nodes = MockTensor([])
        empty_losses = MockTensor([])
        
        result1 = tracker.update_node_info(empty_nodes, empty_losses, None, None, epoch=1)
        
        # æµ‹è¯•Noneå€¼
        node_ids = MockTensor([0, 1])
        losses = MockTensor([0.1, 0.2])
        
        result2 = tracker.update_node_info(node_ids, losses, None, None, epoch=1)
        
        if result1 and result2:
            print("âœ“ è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")
            return True
        else:
            print("âœ— è¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— è¾¹ç•Œæƒ…å†µæµ‹è¯•å¼‚å¸¸: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ç®€å•æµ‹è¯•...")
    print("=" * 40)
    
    tests = [
        test_basic_functionality,
        test_edge_cases
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                print(f"æµ‹è¯• {test_func.__name__} å¤±è´¥")
        except Exception as e:
            print(f"æµ‹è¯• {test_func.__name__} å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 40)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åŸºæœ¬ä¿®å¤æˆåŠŸã€‚")
        print("\nç°åœ¨å¯ä»¥å°è¯•è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒäº†ã€‚")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚")

if __name__ == "__main__":
    main()
