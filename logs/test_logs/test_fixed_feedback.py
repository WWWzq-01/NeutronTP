#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„ä¿¡æ¯äº’é¦ˆç³»ç»Ÿ
"""

import torch
import numpy as np
from info_feedback_system import InfoFeedbackSystem, NodeConvergenceTracker, AdaptiveSampler
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def test_edge_cases_fixed():
    """æµ‹è¯•ä¿®å¤åçš„è¾¹ç•Œæƒ…å†µ"""
    print("æµ‹è¯•ä¿®å¤åçš„è¾¹ç•Œæƒ…å†µ...")
    
    device = torch.device('cpu')
    feedback_system = InfoFeedbackSystem(num_nodes=100, device=device, enable_feedback=True)
    
    try:
        # æµ‹è¯•ç©ºè®­ç»ƒæ©ç 
        print("  æµ‹è¯•ç©ºè®­ç»ƒæ©ç ...")
        empty_mask = torch.zeros(100, dtype=torch.bool)
        batch_nodes = feedback_system.get_adaptive_batch(batch_size=10, epoch=1, train_mask=empty_mask)
        
        if len(batch_nodes) == 0:
            print("    âœ“ ç©ºè®­ç»ƒæ©ç å¤„ç†æˆåŠŸï¼Œè¿”å›ç©ºbatch")
        else:
            print(f"    âœ— ç©ºè®­ç»ƒæ©ç å¤„ç†å¤±è´¥ï¼Œè¿”å›äº† {len(batch_nodes)} ä¸ªèŠ‚ç‚¹")
            return False
        
        # æµ‹è¯•Noneå€¼å¤„ç†
        print("  æµ‹è¯•Noneå€¼å¤„ç†...")
        feedback_info = feedback_system.process_feedback(
            torch.tensor([]), torch.tensor([]), None, None, epoch=1
        )
        print("    âœ“ Noneå€¼å¤„ç†æˆåŠŸ")
        
        # æµ‹è¯•å°batch_size
        print("  æµ‹è¯•å°batch_size...")
        small_mask = torch.zeros(100, dtype=torch.bool)
        small_mask[:5] = True  # åªæœ‰5ä¸ªè®­ç»ƒèŠ‚ç‚¹
        
        batch_nodes = feedback_system.get_adaptive_batch(batch_size=10, epoch=1, train_mask=small_mask)
        if len(batch_nodes) == 5:  # åº”è¯¥è¿”å›æ‰€æœ‰5ä¸ªèŠ‚ç‚¹
            print("    âœ“ å°batch_sizeå¤„ç†æˆåŠŸ")
        else:
            print(f"    âœ— å°batch_sizeå¤„ç†å¤±è´¥ï¼ŒæœŸæœ›5ä¸ªèŠ‚ç‚¹ï¼Œå®é™…{len(batch_nodes)}ä¸ª")
            return False
        
        print("âœ“ è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— è¾¹ç•Œæƒ…å†µæµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_sampling_strategies_fixed():
    """æµ‹è¯•ä¿®å¤åçš„é‡‡æ ·ç­–ç•¥"""
    print("\næµ‹è¯•ä¿®å¤åçš„é‡‡æ ·ç­–ç•¥...")
    
    num_nodes = 500
    device = torch.device('cpu')
    
    # åˆ›å»ºæ”¶æ•›è·Ÿè¸ªå™¨
    convergence_tracker = NodeConvergenceTracker(num_nodes, embedding_dim=64)
    
    # æµ‹è¯•ä¸åŒçš„é‡‡æ ·ç­–ç•¥
    strategies = ['adaptive_importance', 'convergence_aware', 'random']
    
    for strategy in strategies:
        print(f"  æµ‹è¯•ç­–ç•¥: {strategy}")
        
        try:
            # åˆ›å»ºé‡‡æ ·å™¨
            sampler = AdaptiveSampler(num_nodes, convergence_tracker, strategy)
            
            # æ¨¡æ‹Ÿä¸€äº›èŠ‚ç‚¹æ”¶æ•›
            for i in range(100):
                convergence_tracker.converged_nodes.add(i)
            
            # åˆ›å»ºè®­ç»ƒæ©ç 
            train_mask = torch.zeros(num_nodes, dtype=torch.bool)
            train_mask[:200] = True  # 200ä¸ªè®­ç»ƒèŠ‚ç‚¹
            
            # æµ‹è¯•é‡‡æ ·
            batch_size = 100
            epoch = 10
            
            sampled_nodes = sampler.sample_nodes(batch_size, epoch, train_mask)
            
            if len(sampled_nodes) == batch_size:
                converged_in_batch = sum(1 for n in sampled_nodes if n.item() in convergence_tracker.converged_nodes)
                print(f"    âœ“ é‡‡æ ·æˆåŠŸï¼Œbatchå¤§å°: {len(sampled_nodes)}, æ”¶æ•›èŠ‚ç‚¹: {converged_in_batch}")
            else:
                print(f"    âœ— é‡‡æ ·å¤±è´¥ï¼ŒæœŸæœ›{batch_size}ä¸ªèŠ‚ç‚¹ï¼Œå®é™…{len(sampled_nodes)}ä¸ª")
                return False
                
        except Exception as e:
            print(f"    âœ— ç­–ç•¥ {strategy} æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    print("âœ“ é‡‡æ ·ç­–ç•¥æµ‹è¯•é€šè¿‡")
    return True

def test_feedback_processing_fixed():
    """æµ‹è¯•ä¿®å¤åçš„åé¦ˆå¤„ç†"""
    print("\næµ‹è¯•ä¿®å¤åçš„åé¦ˆå¤„ç†...")
    
    device = torch.device('cpu')
    feedback_system = InfoFeedbackSystem(num_nodes=200, device=device, enable_feedback=True)
    
    try:
        # åˆ›å»ºè®­ç»ƒæ©ç 
        train_mask = torch.zeros(200, dtype=torch.bool)
        train_mask[:150] = True  # 150ä¸ªè®­ç»ƒèŠ‚ç‚¹
        
        # æµ‹è¯•æ­£å¸¸æƒ…å†µ
        print("  æµ‹è¯•æ­£å¸¸åé¦ˆå¤„ç†...")
        batch_nodes = feedback_system.get_adaptive_batch(batch_size=50, epoch=1, train_mask=train_mask)
        
        if len(batch_nodes) > 0:
            batch_losses = torch.rand(len(batch_nodes))
            batch_gradients = batch_losses.clone()  # ä½¿ç”¨æŸå¤±ä½œä¸ºæ¢¯åº¦
            batch_embeddings = torch.randn(len(batch_nodes), 64)
            
            feedback_info = feedback_system.process_feedback(
                batch_nodes, batch_losses, batch_gradients, batch_embeddings, epoch=1
            )
            
            if feedback_info:
                print(f"    âœ“ æ­£å¸¸åé¦ˆå¤„ç†æˆåŠŸï¼Œæ”¶æ•›ç‡: {feedback_info['convergence_rate']:.3f}")
            else:
                print("    âœ— æ­£å¸¸åé¦ˆå¤„ç†å¤±è´¥")
                return False
        else:
            print("    âœ— æ— æ³•è·å–batch")
            return False
        
        # æµ‹è¯•ç©ºbatch
        print("  æµ‹è¯•ç©ºbatchå¤„ç†...")
        empty_batch = torch.tensor([], dtype=torch.long)
        empty_losses = torch.tensor([])
        empty_gradients = torch.tensor([])
        empty_embeddings = torch.tensor([])
        
        feedback_info = feedback_system.process_feedback(
            empty_batch, empty_losses, empty_gradients, empty_embeddings, epoch=1
        )
        
        if feedback_info:
            print(f"    âœ“ ç©ºbatchå¤„ç†æˆåŠŸï¼Œæ”¶æ•›ç‡: {feedback_info['convergence_rate']:.3f}")
        else:
            print("    âœ— ç©ºbatchå¤„ç†å¤±è´¥")
            return False
        
        print("âœ“ åé¦ˆå¤„ç†æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— åé¦ˆå¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•ä¿®å¤åçš„ä¿¡æ¯äº’é¦ˆç³»ç»Ÿ...")
    print("=" * 60)
    
    tests = [
        test_edge_cases_fixed,
        test_sampling_strategies_fixed,
        test_feedback_processing_fixed
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                print(f"æµ‹è¯• {test_func.__name__} å¤±è´¥")
        except Exception as e:
            print(f"æµ‹è¯• {test_func.__name__} å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 60)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¾¹ç•Œæƒ…å†µä¿®å¤æˆåŠŸã€‚")
        print("\nç°åœ¨å¯ä»¥å®‰å…¨åœ°è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒäº†ã€‚")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚")
    
    return passed == total

if __name__ == "__main__":
    main()
