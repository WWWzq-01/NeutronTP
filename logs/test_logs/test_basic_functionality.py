#!/usr/bin/env python3
"""
åŸºæœ¬åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import torch
import time
from info_feedback_system import InfoFeedbackSystem

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("=== æµ‹è¯•åŸºæœ¬åŠŸèƒ½ ===")
    
    # ä½¿ç”¨CPUè®¾å¤‡è¿›è¡Œæµ‹è¯•
    device = torch.device('cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    num_nodes = 1000
    embedding_dim = 32
    
    try:
        # åˆ›å»ºç³»ç»Ÿ
        system = InfoFeedbackSystem(
            num_nodes=num_nodes,
            device=device,
            enable_feedback=True,
            feedback_batch_cap=200,
            sampler_candidate_pool_size=500,
            keep_sampling_stats=False,
            similarity_threshold=0.95,
            patience=3,
            min_epochs=2,
            sampling_strategy='no_importance'
        )
        print("âœ… ç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 100
        node_ids = torch.arange(batch_size, device=device)
        losses = torch.rand(batch_size, device=device)
        gradients = torch.rand(batch_size, device=device)
        embeddings = torch.randn(batch_size, embedding_dim, device=device)
        print("âœ… æµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åé¦ˆå¤„ç†
        print("\n--- æµ‹è¯•åé¦ˆå¤„ç† ---")
        for epoch in range(5):
            feedback_info = system.process_feedback(
                node_ids, losses, gradients, embeddings, epoch
            )
            print(f"Epoch {epoch}: {feedback_info['converged_nodes_count']} nodes converged, "
                  f"feedback_batch_size: {feedback_info.get('feedback_batch_size', 'N/A')}")
        
        # æµ‹è¯•é‡‡æ ·
        print("\n--- æµ‹è¯•é‡‡æ · ---")
        train_mask = torch.ones(num_nodes, dtype=torch.bool, device=device)
        batch = system.get_adaptive_batch(batch_size, 5, train_mask)
        print(f"é‡‡æ ·æˆåŠŸï¼Œbatchå¤§å°: {len(batch)}")
        
        # æµ‹è¯•çŠ¶æ€è·å–
        print("\n--- æµ‹è¯•çŠ¶æ€è·å– ---")
        status = system.get_status()
        print(f"çŠ¶æ€: {status}")
        
        print("\nâœ… æ‰€æœ‰åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_cuda_functionality():
    """æµ‹è¯•CUDAåŠŸèƒ½ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    if not torch.cuda.is_available():
        print("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡CUDAæµ‹è¯•")
        return True
    
    print("\n=== æµ‹è¯•CUDAåŠŸèƒ½ ===")
    
    device = torch.device('cuda:0')
    print(f"ä½¿ç”¨CUDAè®¾å¤‡: {device}")
    
    num_nodes = 500
    embedding_dim = 16
    
    try:
        # åˆ›å»ºç³»ç»Ÿ
        system = InfoFeedbackSystem(
            num_nodes=num_nodes,
            device=device,
            enable_feedback=True,
            feedback_batch_cap=100,
            sampler_candidate_pool_size=200,
            keep_sampling_stats=False,
            similarity_threshold=0.95,
            patience=3,
            min_epochs=2,
            sampling_strategy='no_importance'
        )
        print("âœ… CUDAç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 50
        node_ids = torch.arange(batch_size, device=device)
        losses = torch.rand(batch_size, device=device)
        gradients = torch.rand(batch_size, device=device)
        embeddings = torch.randn(batch_size, embedding_dim, device=device)
        print("âœ… CUDAæµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åé¦ˆå¤„ç†
        feedback_info = system.process_feedback(
            node_ids, losses, gradients, embeddings, 0
        )
        print(f"âœ… CUDAåé¦ˆå¤„ç†æˆåŠŸ: {feedback_info['converged_nodes_count']} nodes converged")
        
        # æµ‹è¯•é‡‡æ ·
        train_mask = torch.ones(num_nodes, dtype=torch.bool, device=device)
        batch = system.get_adaptive_batch(batch_size, 0, train_mask)
        print(f"âœ… CUDAé‡‡æ ·æˆåŠŸï¼Œbatchå¤§å°: {len(batch)}")
        
        print("âœ… æ‰€æœ‰CUDAåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ CUDAæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•ä¿¡æ¯äº’é¦ˆç³»ç»Ÿ...")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    basic_success = test_basic_functionality()
    
    # æµ‹è¯•CUDAåŠŸèƒ½
    cuda_success = test_cuda_functionality()
    
    if basic_success and cuda_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
    else:
        print("\nğŸ’¥ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤")

if __name__ == "__main__":
    main()
