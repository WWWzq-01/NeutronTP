#!/usr/bin/env python3
"""
å…¨é¢çš„ä¿¡æ¯äº’é¦ˆç³»ç»Ÿæµ‹è¯•è„šæœ¬
"""

import torch
import numpy as np
from info_feedback_system import InfoFeedbackSystem, NodeConvergenceTracker, AdaptiveSampler
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name_s)s - %(levelname)s - %(message)s')

def test_empty_tensor_handling():
    """æµ‹è¯•ç©ºå¼ é‡å¤„ç†"""
    print("æµ‹è¯•ç©ºå¼ é‡å¤„ç†...")
    
    try:
        # åˆ›å»ºæ”¶æ•›è·Ÿè¸ªå™¨
        tracker = NodeConvergenceTracker(num_nodes=100, embedding_dim=64)
        
        # æµ‹è¯•ç©ºå¼ é‡
        empty_node_ids = torch.tensor([], dtype=torch.long)
        empty_losses = torch.tensor([])
        empty_gradients = torch.tensor([])
        empty_embeddings = torch.tensor([])
        
        # è¿™åº”è¯¥ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        tracker.update_node_info(empty_node_ids, empty_losses, empty_gradients, empty_embeddings, epoch=1)
        print("  âœ“ ç©ºå¼ é‡å¤„ç†æˆåŠŸ")
        
        # æµ‹è¯•Noneå€¼
        tracker.update_node_info(empty_node_ids, empty_losses, None, None, epoch=1)
        print("  âœ“ Noneå€¼å¤„ç†æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"  âœ— ç©ºå¼ é‡å¤„ç†å¤±è´¥: {e}")
        return False

def test_edge_case_sampling():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µé‡‡æ ·"""
    print("\næµ‹è¯•è¾¹ç•Œæƒ…å†µé‡‡æ ·...")
    
    try:
        num_nodes = 100
        device = torch.device('cpu')
        
        # åˆ›å»ºä¿¡æ¯äº’é¦ˆç³»ç»Ÿ
        feedback_system = InfoFeedbackSystem(num_nodes, device, enable_feedback=True)
        
        # æµ‹è¯•1: ç©ºè®­ç»ƒæ©ç 
        print("  æµ‹è¯•1: ç©ºè®­ç»ƒæ©ç ")
        empty_mask = torch.zeros(num_nodes, dtype=torch.bool)
        batch_nodes = feedback_system.get_adaptive_batch(batch_size=10, epoch=1, train_mask=empty_mask)
        
        if len(batch_nodes) == 0:
            print("    âœ“ ç©ºè®­ç»ƒæ©ç å¤„ç†æˆåŠŸ")
        else:
            print(f"    âœ— ç©ºè®­ç»ƒæ©ç å¤„ç†å¤±è´¥ï¼Œè¿”å›äº† {len(batch_nodes)} ä¸ªèŠ‚ç‚¹")
            return False
        
        # æµ‹è¯•2: å°è®­ç»ƒæ©ç 
        print("  æµ‹è¯•2: å°è®­ç»ƒæ©ç ")
        small_mask = torch.zeros(num_nodes, dtype=torch.bool)
        small_mask[:5] = True  # åªæœ‰5ä¸ªè®­ç»ƒèŠ‚ç‚¹
        
        batch_nodes = feedback_system.get_adaptive_batch(batch_size=10, epoch=1, train_mask=small_mask)
        if len(batch_nodes) == 5:
            print("    âœ“ å°è®­ç»ƒæ©ç å¤„ç†æˆåŠŸ")
        else:
            print(f"    âœ— å°è®­ç»ƒæ©ç å¤„ç†å¤±è´¥ï¼ŒæœŸæœ›5ä¸ªèŠ‚ç‚¹ï¼Œå®é™…{len(batch_nodes)}ä¸ª")
            return False
        
        # æµ‹è¯•3: æ­£å¸¸è®­ç»ƒæ©ç 
        print("  æµ‹è¯•3: æ­£å¸¸è®­ç»ƒæ©ç ")
        normal_mask = torch.zeros(num_nodes, dtype=torch.bool)
        normal_mask[:50] = True  # 50ä¸ªè®­ç»ƒèŠ‚ç‚¹
        
        batch_nodes = feedback_system.get_adaptive_batch(batch_size=20, epoch=1, train_mask=normal_mask)
        if len(batch_nodes) == 20:
            print("    âœ“ æ­£å¸¸è®­ç»ƒæ©ç å¤„ç†æˆåŠŸ")
        else:
            print(f"    âœ— æ­£å¸¸è®­ç»ƒæ©ç å¤„ç†å¤±è´¥ï¼ŒæœŸæœ›20ä¸ªèŠ‚ç‚¹ï¼Œå®é™…{len(batch_nodes)}ä¸ª")
            return False
        
        print("  âœ“ è¾¹ç•Œæƒ…å†µé‡‡æ ·æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"  âœ— è¾¹ç•Œæƒ…å†µé‡‡æ ·æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_feedback_processing_edge_cases():
    """æµ‹è¯•åé¦ˆå¤„ç†çš„è¾¹ç•Œæƒ…å†µ"""
    print("\næµ‹è¯•åé¦ˆå¤„ç†çš„è¾¹ç•Œæƒ…å†µ...")
    
    try:
        device = torch.device('cpu')
        feedback_system = InfoFeedbackSystem(num_nodes=200, device=device, enable_feedback=True)
        
        # æµ‹è¯•1: ç©ºbatchåé¦ˆ
        print("  æµ‹è¯•1: ç©ºbatchåé¦ˆ")
        empty_batch = torch.tensor([], dtype=torch.long)
        empty_losses = torch.tensor([])
        empty_gradients = torch.tensor([])
        empty_embeddings = torch.tensor([])
        
        feedback_info = feedback_system.process_feedback(
            empty_batch, empty_losses, empty_gradients, empty_embeddings, epoch=1
        )
        
        if feedback_info and feedback_info['convergence_rate'] == 0.0:
            print("    âœ“ ç©ºbatchåé¦ˆå¤„ç†æˆåŠŸ")
        else:
            print("    âœ— ç©ºbatchåé¦ˆå¤„ç†å¤±è´¥")
            return False
        
        # æµ‹è¯•2: å•ä¸ªèŠ‚ç‚¹åé¦ˆ
        print("  æµ‹è¯•2: å•ä¸ªèŠ‚ç‚¹åé¦ˆ")
        single_batch = torch.tensor([0], dtype=torch.long)
        single_losses = torch.tensor([0.5])
        single_gradients = torch.tensor([0.1])
        single_embeddings = torch.randn(1, 64)
        
        feedback_info = feedback_system.process_feedback(
            single_batch, single_losses, single_gradients, single_embeddings, epoch=1
        )
        
        if feedback_info:
            print(f"    âœ“ å•ä¸ªèŠ‚ç‚¹åé¦ˆå¤„ç†æˆåŠŸï¼Œæ”¶æ•›ç‡: {feedback_info['convergence_rate']:.3f}")
        else:
            print("    âœ— å•ä¸ªèŠ‚ç‚¹åé¦ˆå¤„ç†å¤±è´¥")
            return False
        
        # æµ‹è¯•3: æ­£å¸¸batchåé¦ˆ
        print("  æµ‹è¯•3: æ­£å¸¸batchåé¦ˆ")
        normal_batch = torch.tensor([0, 1, 2, 3, 4], dtype=torch.long)
        normal_losses = torch.tensor([0.5, 0.3, 0.8, 0.2, 0.6])
        normal_gradients = torch.tensor([0.1, 0.05, 0.15, 0.02, 0.12])
        normal_embeddings = torch.randn(5, 64)
        
        feedback_info = feedback_system.process_feedback(
            normal_batch, normal_losses, normal_gradients, normal_embeddings, epoch=1
        )
        
        if feedback_info:
            print(f"    âœ“ æ­£å¸¸batchåé¦ˆå¤„ç†æˆåŠŸï¼Œæ”¶æ•›ç‡: {feedback_info['convergence_rate']:.3f}")
        else:
            print("    âœ— æ­£å¸¸batchåé¦ˆå¤„ç†å¤±è´¥")
            return False
        
        print("  âœ“ åé¦ˆå¤„ç†è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"  âœ— åé¦ˆå¤„ç†è¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_sampling_strategies_comprehensive():
    """æµ‹è¯•æ‰€æœ‰é‡‡æ ·ç­–ç•¥"""
    print("\næµ‹è¯•æ‰€æœ‰é‡‡æ ·ç­–ç•¥...")
    
    try:
        num_nodes = 500
        device = torch.device('cpu')
        
        # åˆ›å»ºæ”¶æ•›è·Ÿè¸ªå™¨
        convergence_tracker = NodeConvergenceTracker(num_nodes, embedding_dim=64)
        
        # æ¨¡æ‹Ÿä¸€äº›èŠ‚ç‚¹æ”¶æ•›
        for i in range(100):
            convergence_tracker.converged_nodes.add(i)
        
        # æµ‹è¯•æ‰€æœ‰ç­–ç•¥
        strategies = ['adaptive_importance', 'convergence_aware', 'random']
        
        for strategy in strategies:
            print(f"  æµ‹è¯•ç­–ç•¥: {strategy}")
            
            # åˆ›å»ºé‡‡æ ·å™¨
            sampler = AdaptiveSampler(num_nodes, convergence_tracker, strategy)
            
            # åˆ›å»ºè®­ç»ƒæ©ç 
            train_mask = torch.zeros(num_nodes, dtype=torch.bool)
            train_mask[:200] = True  # 200ä¸ªè®­ç»ƒèŠ‚ç‚¹
            
            # æµ‹è¯•ä¸åŒbatch_size
            for batch_size in [10, 50, 100]:
                try:
                    sampled_nodes = sampler.sample_nodes(batch_size, epoch=10, train_mask=train_mask)
                    
                    if len(sampled_nodes) == batch_size:
                        converged_in_batch = sum(1 for n in sampled_nodes if n.item() in convergence_tracker.converged_nodes)
                        print(f"    âœ“ batch_size={batch_size}: é‡‡æ ·æˆåŠŸï¼Œæ”¶æ•›èŠ‚ç‚¹: {converged_in_batch}")
                    else:
                        print(f"    âœ— batch_size={batch_size}: é‡‡æ ·å¤±è´¥ï¼ŒæœŸæœ›{batch_size}ä¸ªèŠ‚ç‚¹ï¼Œå®é™…{len(sampled_nodes)}ä¸ª")
                        return False
                        
                except Exception as e:
                    print(f"    âœ— batch_size={batch_size}: é‡‡æ ·å¼‚å¸¸: {e}")
                    return False
        
        print("  âœ“ é‡‡æ ·ç­–ç•¥æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"  âœ— é‡‡æ ·ç­–ç•¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_system_integration():
    """æµ‹è¯•ç³»ç»Ÿé›†æˆ"""
    print("\næµ‹è¯•ç³»ç»Ÿé›†æˆ...")
    
    try:
        device = torch.device('cpu')
        feedback_system = InfoFeedbackSystem(num_nodes=1000, device=device, enable_feedback=True)
        
        # åˆ›å»ºè®­ç»ƒæ©ç 
        train_mask = torch.zeros(1000, dtype=torch.bool)
        train_mask[:800] = True  # 800ä¸ªè®­ç»ƒèŠ‚ç‚¹
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„è®­ç»ƒæµç¨‹
        print("  æ¨¡æ‹Ÿå®Œæ•´è®­ç»ƒæµç¨‹...")
        
        for epoch in range(5):
            # è·å–batch
            batch_nodes = feedback_system.get_adaptive_batch(batch_size=100, epoch=epoch, train_mask=train_mask)
            
            if len(batch_nodes) > 0:
                # æ¨¡æ‹Ÿè®­ç»ƒåé¦ˆ
                batch_losses = torch.rand(len(batch_nodes))
                batch_gradients = batch_losses.clone()
                batch_embeddings = torch.randn(len(batch_nodes), 64)
                
                # å¤„ç†åé¦ˆ
                feedback_info = feedback_system.process_feedback(
                    batch_nodes, batch_losses, batch_gradients, batch_embeddings, epoch
                )
                
                if feedback_info:
                    print(f"    Epoch {epoch}: æ”¶æ•›ç‡ {feedback_info['convergence_rate']:.3f}")
                else:
                    print(f"    Epoch {epoch}: åé¦ˆå¤„ç†å¤±è´¥")
                    return False
            else:
                print(f"    Epoch {epoch}: ç©ºbatch")
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        status = feedback_system.get_status()
        print(f"  æœ€ç»ˆç³»ç»ŸçŠ¶æ€: {status}")
        
        print("  âœ“ ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"  âœ— ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹å…¨é¢æµ‹è¯•ä¿¡æ¯äº’é¦ˆç³»ç»Ÿ...")
    print("=" * 70)
    
    tests = [
        test_empty_tensor_handling,
        test_edge_case_sampling,
        test_feedback_processing_edge_cases,
        test_sampling_strategies_comprehensive,
        test_system_integration
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                print(f"æµ‹è¯• {test_func.__name__} å¤±è´¥")
        except Exception as e:
            print(f"æµ‹è¯• {test_func.__name__} å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 70)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿä¿®å¤å®Œæˆï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨ã€‚")
        print("\nç°åœ¨å¯ä»¥è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒäº†ï¼")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚")
    
    return passed == total

if __name__ == "__main__":
    main()
